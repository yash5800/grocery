{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782dd81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: sentence-transformers in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: langchain in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: google-generativeai in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: python-dotenv in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-community in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: flask in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: flask-cors in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (6.0.0)\n",
      "Requirement already satisfied: langchain_google_genai in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (2.0.10)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from faiss-cpu) (2.2.6)\n",
      "Requirement already satisfied: packaging in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from sentence-transformers) (0.32.3)\n",
      "Requirement already satisfied: Pillow in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langchain) (0.3.63)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langchain) (0.3.43)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langchain) (2.11.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-generativeai) (2.170.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-generativeai) (2.40.2)\n",
      "Requirement already satisfied: protobuf in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langchain-community) (3.12.6)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langchain-community) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from flask) (8.2.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from flask) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from flask) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langchain_google_genai) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
      "Requirement already satisfied: colorama in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: filelock in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: setuptools in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: anyio in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\projects\\ge\\server\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu sentence-transformers langchain google-generativeai python-dotenv langchain-community flask flask-cors langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1088d2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\GE\\server\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\yaswa\\AppData\\Local\\Temp\\ipykernel_8576\\1982620398.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  hf_embedding = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains import ConversationChain\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "hf_embedding = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "product_vector = FAISS.load_local(\n",
    "    folder_path=\"Product_Vector\",\n",
    "    embeddings=hf_embedding,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b28b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "d = [\n",
    "  'ID:12  Name:pesara pappu | Moong Dal  URL:pesara_pappu.jpg',\n",
    "  'ID:12  Name:pesara pappu | Moong Dal  URL:pesara_pappu.jpg',\n",
    "  'ID:18  Name:senaga pappu | Channa Dal  URL:senaga_pappu.jpg'\n",
    "]\n",
    "\n",
    "def json_converter(ls):\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    for line in ls:\n",
    "        item = {}\n",
    "        for parts in line.split(\"  \"):\n",
    "            key,val = parts.split(\":\")\n",
    "            item[key.strip()] = val.strip()\n",
    "        temp.append(item)\n",
    "    return json.dumps(temp,indent=2)\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70760624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaswa\\AppData\\Local\\Temp\\ipykernel_8576\\2837595436.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = VectorStoreRetrieverMemory(retriever=product_vector.as_retriever())\n",
      "C:\\Users\\yaswa\\AppData\\Local\\Temp\\ipykernel_8576\\2837595436.py:5: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  coversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash',temperature=0)\n",
    "\n",
    "memory = VectorStoreRetrieverMemory(retriever=product_vector.as_retriever())\n",
    "\n",
    "coversation = ConversationChain(\n",
    "  llm=llm,\n",
    "  memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5359ce50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, I can provide you with the items that contain \"poppu\" in their name, in object format. Based on the data I have, here's the information:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"id\": 12,\n",
      "    \"name\": \"pesara pappu | Moong Dal\",\n",
      "    \"url\": \"pesara_pappu.jpg\",\n",
      "    \"itemform\": \"raw\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": 11,\n",
      "    \"name\": \"Vedaka Popular Toor Dal | kandipappu\",\n",
      "    \"url\": \"kandipappu.jpg\",\n",
      "    \"itemform\": \"raw\"\n",
      "  },\n",
      "    {\n",
      "    \"id\": 18,\n",
      "    \"name\": \"senaga pappu | Channa Dal\",\n",
      "    \"url\": \"senaga_pappu.jpg\",\n",
      "    \"itemform\": \"raw\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "I've included all the entries where \"poppu\" or \"pappu\" appears in the name. Let me know if you need anything else!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res = coversation.predict(input='give me in object formate only item:'+'poppu')\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae64b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType,initialize_agent,AgentExecutor\n",
    "from langchain.tools import Tool\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "def json_converter(ls):\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    for line in ls:\n",
    "        item = {}\n",
    "        for parts in line.lower().split(\"  \"):\n",
    "            key,val = parts.split(\":\")\n",
    "            item[key.strip()] = val.strip()\n",
    "        temp.append(item)\n",
    "        for i in temp:\n",
    "          i['quantity']=1\n",
    "          i['weight'] = 100\n",
    "    return temp\n",
    "\n",
    "\n",
    "def sim_wrapper(input_str):\n",
    "    print(input_str) \n",
    "    try:\n",
    "        if 'k=' in input_str:\n",
    "            res1,res2 = input_str.split(',')\n",
    "            return sim(res1.strip(),(int(res2.strip().replace('k=',''))))\n",
    "        elif not ',' in input_str :\n",
    "          return sim(input_str)\n",
    "        else:\n",
    "          raise ZeroDivisionError\n",
    "    except:\n",
    "        return 'input must be like `itemname,k=3` .'\n",
    "    \n",
    "\n",
    "def sim(product,k=1):\n",
    "    print(product,k)\n",
    "    docs2 = product_vector.similarity_search(product, k=k)\n",
    "    combined_context = \"\\n\".join([d.page_content for d in docs2])\n",
    "    \n",
    "    print(combined_context)\n",
    "    \n",
    "    return json_converter(combined_context.lower().split('\\n'))\n",
    "  \n",
    "search_tool = Tool(\n",
    "   name='SearchProducts',\n",
    "   func=sim_wrapper,\n",
    "    description=(\n",
    "        \"Use this tool to search for products. It takes two arguments: \"\n",
    "        \"1) product name (string), and \"\n",
    "        \"2) k (number of results to return). \"\n",
    "        \"If user asks for product details or examples (like 'what Pappu items do you have?'), set k value based on preference. \"\n",
    "        \"If user asks to add products to cart, return JSON response of those products. \"\n",
    "        \"Default k is 1.\"\n",
    "    )\n",
    ")\n",
    "    \n",
    "import wikipedia\n",
    "def wiki_summary(topic:str) -> str:\n",
    "  try:\n",
    "    return wikipedia.summary(topic,sentences=2)\n",
    "  except Exception as e:\n",
    "    return e\n",
    "    \n",
    "wiki_tool = Tool(\n",
    "  name='WikiSummary',\n",
    "  func=wiki_summary,\n",
    "  description=\"Use this to get short summary on any product from wikipedia. Input should be the item name.\"\n",
    ")\n",
    "\n",
    "def chat_bot(query):\n",
    "  response = llm.invoke(query)\n",
    "  return str(response)\n",
    "\n",
    "chat_tool = Tool(\n",
    "  name=\"GeminiChat\",\n",
    "  func=chat_bot,\n",
    "  description=\"Use this tool for general coversation ,answering question,checking products types like oil, liquid, solid or not ,etc..\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa2b2d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pappu 5\n",
      "id:12  name:pesara pappu | Moong Dal  url:pesara_pappu.jpg  itemform:raw\n",
      "id:18  name:senaga pappu | Channa Dal  url:senaga_pappu.jpg  itemform:raw\n",
      "id:11  name:Vedaka Popular Toor Dal | kandipappu   url:kandipappu.jpg  itemform:raw\n",
      "id:13  name:No Preservatives Whole Moong | pesalu  url:pesalu.jpg  itemform:raw\n",
      "id:8  name:Bague Premium Whole Methi Seeds Dana Fenugreek seed | menthulu  url:menthulu.jpg  itemform:raw\n",
      "[{'id': '12', 'name': 'pesara pappu | moong dal', 'url': 'pesara_pappu.jpg', 'itemform': 'raw', 'quantity': 1, 'weight': 100}, {'id': '18', 'name': 'senaga pappu | channa dal', 'url': 'senaga_pappu.jpg', 'itemform': 'raw', 'quantity': 1, 'weight': 100}, {'id': '11', 'name': 'vedaka popular toor dal | kandipappu', 'url': 'kandipappu.jpg', 'itemform': 'raw', 'quantity': 1, 'weight': 100}, {'id': '13', 'name': 'no preservatives whole moong | pesalu', 'url': 'pesalu.jpg', 'itemform': 'raw', 'quantity': 1, 'weight': 100}, {'id': '8', 'name': 'bague premium whole methi seeds dana fenugreek seed | menthulu', 'url': 'menthulu.jpg', 'itemform': 'raw', 'quantity': 1, 'weight': 100}]\n"
     ]
    }
   ],
   "source": [
    "val = sim('pappu',5)\n",
    "  \n",
    "print(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "190fa2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaswa\\AppData\\Local\\Temp\\ipykernel_8576\\2394252333.py:1: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "agent = initialize_agent(\n",
    "   tools=[search_tool,wiki_tool,chat_tool],\n",
    "   llm=llm,\n",
    "   agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "   system_message=(\n",
    "        \"You must always use the SearchProducts tool with input example: `pappu,k=2` .\"\n",
    "        \"Do not use Python dictionaries or any other format. Only JSON strings.\"\n",
    "        \"You must always use the SearchProducts tool when the user asks about product availability or product details.\"\n",
    "        \"If user asks to add products to the cart, return the output in JSON format. \"\n",
    "        \"If user only asks for information, give a text response summarizing the search results.\"  \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0f6d49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaswa\\AppData\\Local\\Temp\\ipykernel_8576\\2833518875.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key='chat_history',return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key='chat_history',return_messages=True)\n",
    "\n",
    "agent_executer = AgentExecutor.from_agent_and_tools(\n",
    "  tools=[wiki_tool,search_tool,chat_tool],\n",
    "  memory=memory,\n",
    "  agent=agent.agent,\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "559f693b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaswa\\AppData\\Local\\Temp\\ipykernel_8576\\2194290350.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  res = agent_executer.run('find pesara pappu add it to cart')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe user wants to add \"pesara pappu\" to the cart. I need to find the product and return a JSON response.\n",
      "Action: SearchProducts\n",
      "Action Input: pesara pappu\u001b[0mpesara pappu\n",
      "pesara pappu 1\n",
      "id:12  name:pesara pappu | Moong Dal  url:pesara_pappu.jpg  itemform:raw\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3m[{'id': '12', 'name': 'pesara pappu | moong dal', 'url': 'pesara_pappu.jpg', 'itemform': 'raw', 'quantity': 1, 'weight': 100}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found the product \"pesara pappu | moong dal\". Now I need to return the JSON response.\n",
      "Final Answer: ```json\n",
      "[{'id': '12', 'name': 'pesara pappu | moong dal', 'url': 'pesara_pappu.jpg', 'itemform': 'raw', 'quantity': 1, 'weight': 100}]\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "```json\n",
      "[{'id': '12', 'name': 'pesara pappu | moong dal', 'url': 'pesara_pappu.jpg', 'itemform': 'raw', 'quantity': 1, 'weight': 100}]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "res = agent_executer.run('find pesara pappu add it to cart')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b1eee65",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 3 (char 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[32m      8\u001b[39m     json_text = match.group(\u001b[32m1\u001b[39m).strip()\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     parsed_json = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(parsed_json)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\json\\decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python312\\Lib\\json\\decoder.py:353\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[33;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[33;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m \n\u001b[32m    351\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting property name enclosed in double quotes: line 1 column 3 (char 2)"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "pattern = r'```json\\s*(.*?)\\s*```'\n",
    "match = re.search(pattern, res, re.DOTALL)\n",
    "\n",
    "if match:\n",
    "    json_text = match.group(1).strip()\n",
    "    parsed_json = json.loads(json_text)\n",
    "    print(parsed_json)\n",
    "else:\n",
    "    print(\"No JSON block found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76b1ce21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10\n",
      "[\n",
      "  {\n",
      "    \"ID\": \"14\",\n",
      "    \"Name\": \"Vedaka Whole Jeera | gelakarra\",\n",
      "    \"URL\": \"gelakarra.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"ID\": \"16\",\n",
      "    \"Name\": \"Dry Fruit Hub Copra Dry Coconut\",\n",
      "    \"URL\": \"Dry_Coconut.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"ID\": \"11\",\n",
      "    \"Name\": \"Vedaka Popular Toor Dal | kandipappu\",\n",
      "    \"URL\": \"kandipappu.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"ID\": \"4\",\n",
      "    \"Name\": \"sugar\",\n",
      "    \"URL\": \"sugar.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"ID\": \"13\",\n",
      "    \"Name\": \"No Preservatives Whole Moong | pesalu\",\n",
      "    \"URL\": \"pesalu.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"ID\": \"9\",\n",
      "    \"Name\": \"elakulu | Emperor Akbar GI Tagged Alleppey Green Cardamom | Elaichi\",\n",
      "    \"URL\": \"Elaichi.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"ID\": \"18\",\n",
      "    \"Name\": \"senaga pappu | Channa Dal\",\n",
      "    \"URL\": \"senaga_pappu.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"ID\": \"15\",\n",
      "    \"Name\": \"Vedaka Poppy Seeds | gasagasalu\",\n",
      "    \"URL\": \"gasagasalu.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"ID\": \"8\",\n",
      "    \"Name\": \"Bague Premium Whole Methi Seeds Dana Fenugreek seed | menthulu\",\n",
      "    \"URL\": \"menthulu.jpg\"\n",
      "  },\n",
      "  {\n",
      "    \"ID\": \"1\",\n",
      "    \"Name\": \"Aashirvaad Sharbati Atta\",\n",
      "    \"URL\": \"Aashirvaad.jpg\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(sim(\"\",10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c20dee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType,initialize_agent,AgentExecutor\n",
    "from langchain.tools import Tool\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import wikipedia\n",
    "import json\n",
    "import re\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "class Tools_Part():\n",
    "  \n",
    "  def __init__(self):\n",
    "    self.llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash',temperature=0)\n",
    "    self.search_tool = Tool(\n",
    "        name='SearchProducts',\n",
    "        func=self.sim_wrapper,\n",
    "         description=(\n",
    "             \"Use this tool to search for products. It takes two arguments: \"\n",
    "             \"1) product name (string), and \"\n",
    "             \"2) k (number of results to return). \"\n",
    "             \"If user asks for product details or examples (like 'what Pappu items do you have?'), set k value based on preference. \"\n",
    "             \"If user asks to add products to cart, return JSON response of those products. \"\n",
    "             \"Default k is 1.\"\n",
    "             \"If query what to see image include url in responce example: url:'dummy.jpg'\"\n",
    "         )\n",
    "        )\n",
    "    \n",
    "    self.wiki_tool = Tool(\n",
    "           name='WikiSummary',\n",
    "           func=self.wiki_summary,\n",
    "           description=\"Use this to get short summary on any product from wikipedia. Input should be the item name.\"\n",
    "         )\n",
    "    \n",
    "    self.chat_tool = Tool(\n",
    "        name=\"GeminiChat\",\n",
    "        func=self.chat_bot,\n",
    "        description=\"Use this tool for general coversation ,answering question,checking products types like oil, liquid,solid or not ,etc..\"\n",
    "      )\n",
    "    \n",
    "    self.weight_convert = Tool(\n",
    "        name=\"WeightCovert\",\n",
    "        func=self.parse_weight,\n",
    "        description=\"Use this tool for to get Weights in grams from liter to grams, kg to grams, eg: input must be like : 1kg or (value)liter or (value)g\"\n",
    "      )\n",
    "    \n",
    "    self.hf_embedding = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
    "    \n",
    "    self.product_vector = FAISS.load_local(\n",
    "    folder_path=\"Product_Vector\",\n",
    "    embeddings=self.hf_embedding,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "    \n",
    "  \n",
    "  def json_converter(self,ls):\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    for line in ls:\n",
    "        item = {}\n",
    "        for parts in line.lower().split(\"  \"):\n",
    "            key,val = parts.split(\":\")\n",
    "            item[key.strip()] = val.strip()\n",
    "        temp.append(item)\n",
    "        for i in temp:\n",
    "          i['quantity']=1\n",
    "          i['weight'] = 0\n",
    "    return temp\n",
    "\n",
    "\n",
    "  def sim_wrapper(self,input_str):\n",
    "      print(input_str) \n",
    "      try:\n",
    "          if 'k=' in input_str:\n",
    "              res1,res2 = input_str.split(',')\n",
    "              return self.sim(res1.strip(),(int(res2.strip().replace('k=',''))))\n",
    "          elif not ',' in input_str :\n",
    "            return self.sim(input_str)\n",
    "          else:\n",
    "            raise ZeroDivisionError\n",
    "      except:\n",
    "          return 'input must be like `itemname,k=3` .'\n",
    "      \n",
    "  \n",
    "  def sim(self,product,k=1):\n",
    "      print(product,k)\n",
    "      docs2 = self.product_vector.similarity_search(product, k=k)\n",
    "      combined_context = \"\\n\".join([d.page_content for d in docs2])\n",
    "      \n",
    "      return self.json_converter(combined_context.split('\\n'))\n",
    "    \n",
    "  def wiki_summary(self,topic:str) -> str:\n",
    "     try:\n",
    "       return wikipedia.summary(topic,sentences=2)\n",
    "     except Exception as e:\n",
    "       return e\n",
    "  \n",
    "  def chat_bot(self,query):\n",
    "     response = self.llm.invoke(query)\n",
    "     return str(response)\n",
    "   \n",
    "  def pure(self,res):\n",
    "    pattern = r'```json\\s*(.*?)\\s*```'\n",
    "    match = re.search(pattern, res, re.DOTALL)\n",
    "    \n",
    "    if match:\n",
    "        json_text = match.group(1).strip()\n",
    "        parsed_json = json.loads(json_text)\n",
    "        return parsed_json\n",
    "    elif \"[{'id':\" in res:\n",
    "        return json.loads(res.replace('\\'',\"\\\"\"))\n",
    "    else:\n",
    "      return \"No Object Found\"\n",
    "    \n",
    "  def parse_weight(self,weight_text):\n",
    "    \"\"\"\n",
    "    Parse weight text like '1kg' or '1liter' and return numeric weight:\n",
    "    - 1kg ➜ 1000\n",
    "    - 1liter ➜ 910\n",
    "    - 500g ➜ 500\n",
    "    - Plain numbers remain as is.\n",
    "    \"\"\"\n",
    "    weight_text = weight_text.lower().strip()\n",
    "    if weight_text.endswith('kg'):\n",
    "        num = float(weight_text.replace('kg', '').strip())\n",
    "        return int(num * 1000)  # 1kg=1000g\n",
    "    elif weight_text.endswith('g'):\n",
    "        num = float(weight_text.replace('g', '').strip())\n",
    "        return int(num)\n",
    "    elif weight_text.endswith('liter'):\n",
    "        num = float(weight_text.replace('liter', '').strip())\n",
    "        return int(num * 910)  # 1 liter = 910g (as per your case)\n",
    "    else:\n",
    "        try:\n",
    "            return int(weight_text)\n",
    "        except:\n",
    "            return 100  # fallback\n",
    "          \n",
    "      \n",
    "class Agent_Part(Tools_Part):\n",
    "  \n",
    "  def __init__(self):\n",
    "   super().__init__()\n",
    "    \n",
    "   self.memory = ConversationBufferMemory(memory_key='chat_history',return_messages=True)\n",
    "   \n",
    "   self.agent = initialize_agent(\n",
    "    tools=[self.search_tool, self.wiki_tool,self.chat_tool,self.weight_convert],\n",
    "    llm=self.llm,\n",
    "    memory=self.memory,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    system_message=(\n",
    "        \"Rules You Must Follow for each Item this must only contain : id is item id ,name is item name,url is image url,itemform type of item form,quantity is number of items ,weight is weight of the item example ```json {'id': 'itemid', 'name': 'itemname', 'url': 'url', 'itemform': 'raw', 'quantity': 1, 'weight': 100} ```\"\n",
    "        \"Item weight must be only in grams\"\n",
    "        \"You must always use the SearchProducts tool with input example: `pappu,k=2`.\"\n",
    "        \"Do not use Python dictionaries or any other format. Only JSON strings.\"\n",
    "        \"You must always use the SearchProducts tool when the user asks about product availability or product details.\"\n",
    "        \"If the user asks to add products to the cart, return the output in JSON format. example ```json {'id': 'itemid', 'name': 'itemname', 'url': 'url', 'itemform': 'raw', 'quantity': 1, 'weight': 100} ```\"\n",
    "        \"If the user only asks for information, give a text response summarizing the search results.\"\n",
    "        \"You must only follow items in this formate example ```json {'id': 'itemid', 'name': 'itemname', 'url': 'url', 'itemform': 'raw', 'quantity': 1, 'weight': 100} ```\"\n",
    "        \"weight must be in grams only\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "   self.agent_executer = AgentExecutor.from_agent_and_tools(\n",
    "     memory=self.memory,\n",
    "     agent=self.agent.agent,\n",
    "     tools=[self.search_tool,self.wiki_tool,self.chat_tool,self.weight_convert],\n",
    "     verbose=True \n",
    "   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c66e535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe user wants to add 2 1-liter Vijaya oil to the cart. I need to find the product \"Vijaya oil\" and return the JSON response for 2 quantities of 1-liter size.\n",
      "\n",
      "Action: SearchProducts\n",
      "Action Input: Vijaya oil\u001b[0mVijaya oil\n",
      "Vijaya oil 1\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'id': '2', 'name': 'groundnut oil vijaya', 'url': 'groundnut_oil.webp', 'itemform': 'oil', 'quantity': 1, 'weight': 0}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe user wants to add 2 1-liter Vijaya oil to the cart. The search result shows \"groundnut oil vijaya\" with a quantity of 1. I need to update the quantity to 2 and specify the weight as 1 liter. Since the weight is currently 0, I need to convert 1 liter to grams to maintain consistency.\n",
      "\n",
      "Action: WeightCovert\n",
      "Action Input: 1liter\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m910\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the weight of 1 liter of oil is 910 grams. I can now construct the JSON response with the correct quantity and weight.\n",
      "\n",
      "Action: SearchProducts\n",
      "Action Input: groundnut oil vijaya\u001b[0mgroundnut oil vijaya\n",
      "groundnut oil vijaya 1\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'id': '2', 'name': 'groundnut oil vijaya', 'url': 'groundnut_oil.webp', 'itemform': 'oil', 'quantity': 1, 'weight': 0}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the product details and the converted weight. Now I can construct the JSON response with the correct quantity and weight.\n",
      "\n",
      "Final Answer: ```json\n",
      "[\n",
      "  {\n",
      "    \"id\": \"2\",\n",
      "    \"name\": \"groundnut oil vijaya\",\n",
      "    \"url\": \"groundnut_oil.webp\",\n",
      "    \"itemform\": \"oil\",\n",
      "    \"quantity\": 2,\n",
      "    \"weight\": 910\n",
      "  }\n",
      "]\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"id\": \"2\",\n",
      "    \"name\": \"groundnut oil vijaya\",\n",
      "    \"url\": \"groundnut_oil.webp\",\n",
      "    \"itemform\": \"oil\",\n",
      "    \"quantity\": 2,\n",
      "    \"weight\": 910\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "agent_obj = Agent_Part()\n",
    "\n",
    "print(agent_obj.agent_executer.run('add 2 1liter vijaya oil'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3cd306a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "print(agent_obj.weight_convert('1.1liter'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
